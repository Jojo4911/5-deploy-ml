---
title: 5-deploy-ml
emoji: üîÆ
colorFrom: yellow
colorTo: pink
sdk: docker
pinned: false
short_description: Employee Attrition Prediction
---

# Futurisys - POC : Pr√©diction de l'Attrition Employ√© (TechNova Partners)

## üìã Pr√©sentation du Projet

Dans le cadre d'une mission pour **Futurisys**, ce projet vise √† d√©ployer un outil de classification pour l'entreprise TechNova Partners. L'objectif est d'identifier les causes racines derri√®re les d√©missions (attrition) afin de proposer des plans d'action cibl√©s.

Le moteur de pr√©diction repose sur un mod√®le **Random Forest all√©g√©**, optimis√© pour la production. L'application est h√©berg√©e sur Hugging Face Spaces, offrant une interface API robuste et une tra√ßabilit√© compl√®te des pr√©dictions via une base de donn√©es PostgreSQL.

## üöÄ Fonctionnalit√©s

* **API REST** : D√©velopp√©e avec FastAPI pour des performances optimales, rapidit√©, validation automatique avec Pydantic, documentation Swagger native.
* **Mod√®le ML** : Classification binaire (Attrition: Oui/Non) via Random Forest.
* **H√©bergement Cloud** : D√©ploiement continu sur Hugging Face Spaces.
* **Persistance PostgreSQL** : Historisation de chaque pr√©diction (inputs RH et scores d'attrition) pour analyse ult√©rieure. PostgreSQL a √©t√© choisi pour la persistance et l‚Äôint√©grit√© des donn√©es et la scalabilit√©.
* **Validation Pydantic** : Contr√¥le strict de la conformit√© des donn√©es employ√©s envoy√©es √† l'API.
* **Tests & Qualit√©** : Couverture de tests unitaires et fonctionnels avec Pytest.

### üõ°Ô∏è Robustesse et Tol√©rance aux pannes
L'application impl√©mente une strat√©gie de **d√©gradation gracieuse** :
* **En Local** : L'API se connecte √† PostgreSQL et archive chaque requ√™te.
* **Sur le Cloud (Hugging Face)** : Si aucune base de donn√©es n'est configur√©e (ou en cas de panne DB), l'API continue de fournir des pr√©dictions en mode "stateless" (sans persistance), garantissant la disponibilit√© du service.

## üèóÔ∏è Architecture des outils utilis√©s

L‚Äôensemble des outils utilis√©s peuvent √™tre repr√©sent√©s selon la vue d‚Äôensemble suivante :

```mermaid
flowchart TD
    A[üë©‚Äçüíª Utilisateur / Client] -->|Envoie des donn√©es : requ√™te HTTP| B[‚ö° FastAPI - API]
    B --> C[‚úÖ Pydantic - Validation des entr√©es]
    C --> D[üß† Mod√®le ML - Pr√©diction]
    D --> E[(üíæ PostgreSQL - Base de donn√©es)]
    E --> D
    D -->|Renvoie la pr√©diction| B
    B -->|Renvoie la r√©ponse JSON| A

    subgraph Infrastructure
        F[üê≥ Docker - Conteneur]
        G[‚òÅÔ∏è Hugging Face Spaces - H√©bergement]
        H[ü§ñ GitHub Actions - CI/CD]
    end

    F --> B
    H --> F
    H --> G
    G --> B
```

## üíæ Architecture de Donn√©es (PostgreSQL)

Afin d'assurer une tra√ßabilit√© compl√®te et de surveiller le *Data Drift*, nous avons opt√© pour une architecture "Flat Table". Chaque pr√©diction (inputs + outputs) est stock√©e dans une table unique.

Voici le sch√©ma relationnel (Entity-Relationship Diagram) de la table `predictions` :

```mermaid
erDiagram
    PREDICTION_HISTORY {
        INTEGER id PK "Cl√© Primaire (Auto-incr√©ment√©e)"
        TIMESTAMP timestamp "Horodatage de la requ√™te"
        VARCHAR frequence_deplacement "Input : Frequency"
        INTEGER revenu_mensuel "Input : MonthlyIncome"
        VARCHAR heure_supplementaires "Input : OverTime"
        INTEGER distance_domicile_travail "Input : DistanceFromHome"
        INTEGER satisfaction_employee_environnement "Input : EnvironmentSatisfaction"
        INTEGER satisfaction_employee_nature_travail "Input : JobSatisfaction"
        INTEGER satisfaction_employee_equipe "Input : RelationshipSatisfaction"
        INTEGER satisfaction_employee_equilibre_pro_perso "Input : WorkLifeBalance"
        INTEGER annee_experience_totale "Input : TotalWorkingYears"
        INTEGER annees_dans_l_entreprise "Input : YearsAtCompany"
        INTEGER nombre_participation_pee "Input : TrainingTimesLastYear"
        INTEGER age "Input : Age"
        INTEGER annes_sous_responsable_actuel "Input : YearsWithCurrManager"
        INTEGER nombre_experiences_precedentes "Input : NumCompaniesWorked"
        INTEGER note_evaluation_precedente "Input : PerformanceRating"
        VARCHAR prediction "Output : 0 (Reste) ou 1 (D√©mission)"
        FLOAT probability "Output : Score de confiance (0.0 √† 1.0)"
    }
```

## üõ†Ô∏è Installation et Configuration

### Pr√©requis

* Python 3.12+
* PostgreSQL (local ou Docker)
* Git

### Installation locale

1. Cloner le d√©p√¥t :

```bash
git clone [https://github.com/Jojo4911/5-deploy-ml.git](https://github.com/ojo4911/5-deploy-ml.git)
cd futurisys-attrition-app
```

2. Initialiser l'environnement :

Ce projet utilise Poetry pour la gestion des paquets, mais un fichier `requirements.txt` est √©galement fourni.

```
# Via Poetry (Recommand√©)
poetry install
```

```
# OU via Pip
pip install -r requirements.txt
```

3. Configuration de la Base de Donn√©es et des Secrets (.env)

Le projet n√©cessite une base de donn√©es PostgreSQL.

Cr√©ez une base de donn√©es vide nomm√©e projet5_db (via pgAdmin ou psql).

√Ä la racine du projet, cr√©ez un fichier nomm√© .env.

Copiez-y le contenu suivant en adaptant vos identifiants :

```
# Fichier .env
DB_USER=postgres
DB_PASSWORD=votre_mot_de_passe
DB_HOST=localhost
DB_NAME=projet5_db
```

4. Initialisation des Donn√©es

Deux scripts sont √† votre disposition pour pr√©parer l'environnement :

```
# 1. Cr√©er les tables dans la base de donn√©es
poetry run python create_db.py

# 2. Ins√©rer l'historique des donn√©es (Dataset HR - 1470 lignes)
poetry run python insert_data.py
```

## üåç D√©ploiement sur Hugging Face Spaces

L'application est synchronis√©e automatiquement avec Hugging Face.
* **URL du Space** : https://huggingface.co/spaces/thewayofwisedom/5-deploy-ml
* **Configuration** : Le d√©ploiement utilise un environnement Docker pour garantir la reproductibilit√© des pr√©dictions.

## üñ•Ô∏è Utilisation de l'API

### Architecture logique interne de l‚ÄôAPI FastAPI

```mermaid
graph TD
    A[üåê main.py - Point d'entr√©e API]
    A --> B[üì¶ routes/ - D√©finit les endpoints : predict, health...]
    A --> C[üß© models/ - Mod√®le ML & pr√©processeur]
    A --> D[üßæ schemas.py - Classes Pydantic]
    A --> E[üß∞ utils/ - Fonctions utilitaires]
    A --> F[üß™ tests/ - Tests Pytest]
    A --> G[üíæ database/ - Connexion PostgreSQL]

    B --> D
    B --> C
    B --> G
    F --> A
```

### Lancement local

```
uvicorn app.main:app --reload
```

### Exemple de requ√™te (Pr√©diction d'attrition)

L'API attend 15 caract√©ristiques socio-professionnelles de l'employ√© :
```
curl -X 'POST' \
  '[https://votre-space.hf.space/predict](https://votre-space.hf.space/predict)' \
  -H 'X-API-KEY: votre_cle' \
  -H 'Content-Type: application/json' \
  -d '{
  "frequence_deplacement": "Occasionnel",
  "heure_supplementaires": "Non",
  "annees_dans_l_entreprise": 12,
  "nombre_participation_pee": 2,
  "age": 47,
  "revenu_mensuel": 5993,
  "annes_sous_responsable_actuel": 5,
  "distance_domicile_travail": 8,
  "satisfaction_employee_environnement": 2,
  "satisfaction_employee_nature_travail": 4,
  "satisfaction_employee_equipe": 1,
  "satisfaction_employee_equilibre_pro_perso": 3,
  "annee_experience_totale": 8,
  "nombre_experiences_precedentes": 3,
  "note_evaluation_precedente": 3
}'
```

## üìä Structure des Donn√©es (PostgreSQL)

Chaque requ√™te √† l'API est enregistr√©e pour permettre au client TechNova Partners d'auditer les d√©cisions du mod√®le.

Table `predictions`
* `id` : Identifiant unique.
* `employee_features` : Donn√©es envoy√©es (Age, Salaire, etc.) au format JSONB.
* `attrition_probability` : Score de probabilit√© calcul√© par le Random Forest.
* `prediction` : R√©sultat final (0 ou 1).
* `created_at` : Horodatage de la requ√™te.

## üß™ Tests et Fiabilit√©
La robustesse du d√©ploiement est v√©rifi√©e par une suite de tests :
* **Tests Unitaires** : Validation du chargement du mod√®le et des fonctions de pr√©traitement.
* **Tests Fonctionnels** : Simulation d'appels API avec des cas limites (donn√©es manquantes, formats invalides).

```
# Lancer les tests
pytest
# V√©rifier la couverture
pytest --cov=app tests/
```

## üîÑ Pipeline CI/CD

La pipeline CI/CD peut √™tre repr√©sent√©e simplement de la mani√®re suivante :

```mermaid
flowchart LR
    A[üíæ Commit sur GitHub] --> B[üîç GitHub Actions - Lancement pipeline]
    B --> C[üß™ √âtape 1 : Ex√©cution des tests : pytest]
    C --> D[üêç √âtape 2 : V√©rification du code : linting, formatting]
    D --> E[üê≥ √âtape 3 : Build de l'image Docker]
    E --> F[‚òÅÔ∏è √âtape 4 : D√©ploiement sur Hugging Face Spaces]
    F --> G[‚úÖ Application accessible en ligne]

```

Le workflow GitHub Actions assure :

1. La validation du code (Linting & Tests).
2. Le build de l'image Docker.
3. Le push vers le secret `HF_TOKEN` pour mettre √† jour le Space Hugging Face en temps r√©el.

*Livrable r√©alis√© pour le projet d'ing√©nierie IA - Client : Futurisys / Cas d'√©tude : TechNova Partners.*